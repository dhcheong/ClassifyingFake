{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbbedfc2-696e-4333-b0df-d90918f0b9c6",
   "metadata": {},
   "source": [
    "# Creating Features Through Investigation\n",
    "\n",
    "On this page, we will focus on creating new features other than the given columns in the dataset. \n",
    "Let's start with some simple hypothesis and investigate whether we can use our hypothesis to create a new feature.  \n",
    "\n",
    "```{note}\n",
    "This page corresponds to the \"Power Feature\" part of the original project. I will revise and fix some errors in the original project on this page and add new investigations for more features. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12efc2e5-ead1-4aed-9b86-2bca27980ff6",
   "metadata": {},
   "source": [
    "### First Investigation: Relationship Between Location and Fraudulent Posting\n",
    "\n",
    "The first hypothesis we will investigate is that **location, especially state, is related to whether the posting is fraudulent.** For example, many fake job postings might have come from California or New York since those states have more job availability than others due to their high population. If the location is significantly related to the fraudulent variable, we can extract the state from the location and use it as a feature. Let's investigate the relationship and see if the hypothesis is correct.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f43d02e9-a2bb-4423-907b-8ba3bf8845f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "04ea955d-31a1-4304-b5a8-ead2f26689d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US, VA, Virginia Beach</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US, TX, Dallas</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US, NE, Omaha</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US, CA, Los Angeles</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location  fraudulent\n",
       "0  US, VA, Virginia Beach           0\n",
       "1          US, TX, Dallas           0\n",
       "2         NZ, , Auckland            0\n",
       "3           US, NE, Omaha           0\n",
       "4     US, CA, Los Angeles           0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./data/train_set.csv\")\n",
    "data = train_data[[\"location\", \"fraudulent\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "35a1de41-8fc8-4d67-8275-44205f9c287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[\"location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b2d80ec1-690a-45b0-9170-8013bafcd7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_22856\\1345136221.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target.fillna(\"No Location\", inplace = True)\n"
     ]
    }
   ],
   "source": [
    "target.fillna(\"No Location\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "51def6fa-2530-48f8-b545-30f6d4abc91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14304"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3adfacc-17f1-473b-95b5-b79df5a75bbe",
   "metadata": {},
   "source": [
    "To extract the state from the location, let's define the function to make this easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ba26654a-6aa0-4468-96cd-ffbd04dabb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_state(s):\n",
    "    \"\"\" Extract state from the location\"\"\"\n",
    "    \"\"\" The function can be used only when the state is formmated with two capital letter\"\"\"\n",
    "    \"\"\" Input: Series, iterable object\"\"\"\n",
    "    \"\"\" Output: List of States\"\"\"\n",
    "    \n",
    "    result = []    \n",
    "    for i in np.arange(len(s)):\n",
    "        if (s[i].__contains__(\"US\")):\n",
    "            extracted = re.findall(r'[A-Z]{2}', re.sub(r'[US]','',s[i])) \n",
    "            if extracted == []:\n",
    "                extracted = [\"Domestic\"]\n",
    "            result += extracted\n",
    "        else:\n",
    "            if s[i] == [\"No Location\"]:\n",
    "                result += s[i]\n",
    "            elif re.findall(r'[A-Z]{2}', s[i]) != []:\n",
    "                result += [\"Foreign\"]\n",
    "            else:\n",
    "                result += [\"No Location\"]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6f952830-8ba2-40f4-9d7c-791186ba03c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[A-Z]{2}', re.sub(r'[US]','',data[\"location\"][22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "74454e84-9eb9-4b26-9f46-35ed55a42439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VA',\n",
       " 'TX',\n",
       " 'Foreign',\n",
       " 'NE',\n",
       " 'CA',\n",
       " 'NY',\n",
       " 'Foreign',\n",
       " 'OH',\n",
       " 'Foreign',\n",
       " 'MA',\n",
       " 'CA',\n",
       " 'TN',\n",
       " 'Foreign',\n",
       " 'TX',\n",
       " 'Foreign',\n",
       " 'Foreign',\n",
       " 'CO',\n",
       " 'TX',\n",
       " 'CA',\n",
       " 'Foreign',\n",
       " 'Foreign',\n",
       " 'Foreign',\n",
       " 'Domestic']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_state(data[\"location\"][0:23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7cf58302-79f9-464a-acf6-92e8b3048e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extract_state(data[\"location\"][0:185]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fb5d9447-25de-41c3-8d25-66d9a152db07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14133"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extract_state(data[\"location\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f72c7c98-de28-4fbb-b235-7c35407f7ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14717"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extract_state(data[\"location\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb6e0362-17cc-4039-9fd8-6fb28e7339f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'US, VA, Virginia Beach'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"location\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3de14-4c6f-401c-bb45-04bc0af52c03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
