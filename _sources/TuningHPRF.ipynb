{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a5dd58-46a9-4b45-8b74-93cf7bc6bb6a",
   "metadata": {},
   "source": [
    "# Tuning the Hyperparameters of the Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f55ceb-ee92-4e44-a882-cc7761955f73",
   "metadata": {},
   "source": [
    "In this section, we will explore tuning the hyperparameters of the Random Forest model. Here are the parameters that we will tune in this section. \n",
    "\n",
    "```{note}\n",
    "Note that we are using a random forest model from the sklearn package. \n",
    "```\n",
    "\n",
    "* **criterion:** Random Forest model from the sklearn package provide three different measurements for the quality of the tree: \"Gini\" and \"entropy,\". It would be great to know which measurement is a better fit. \n",
    "\n",
    "* **n_estimators:** We usually don't need to tune this variable since more estimators are generally better for a random forest. However, in the original project, we discovered a slight chance of over-fitting with the number of estimators, so I included it. \n",
    "\n",
    "* **max_depth:** We want to tune this variable since the depth of the tree can be closely related to over-fitting.\n",
    "\n",
    "* **max_features:** The rule of thumb of the max_features is the square of the number of features, but we must tune this variable since the number could be more optimal. \n",
    "\n",
    "* **class_weight:** This is very important because our dataset has highly imbalanced numbers of fraudulent and non-fraudulent postings. We need to tune the weight of each class so that we balance our final result. \n",
    "\n",
    "```{note}\n",
    "When we adjust the class_weight, we need to focus more on the recall rate, not the overall accuracy. Since we have much more non-fraudulent postings (95%) than fraudulent postings (5%), even a null classifier that always predicts the posing as non-fraudulent will get 95% accuracy. Since detecting a fraudulent posting is a primary focus of the project, we need to tune the class_weight with the AUC of the ROC curve.\n",
    "```\n",
    "\n",
    "## Procedure:\n",
    "\n",
    "1. n_estimators, max_depth, max_features, and criterion will be tuned using the Hyperopt package, which uses a Bayesian optimization for tuning the hyperparameters.\n",
    "2. class_weight will be tuned using cross-validation with ROC_AUC as a score. \n",
    "3. Since the fraudulent should have more weight than the non-fraudulent, we will choose among {0: 1, 1:1.3}, {0: 1, 1:1.6}, {0: 1, 1:1.9}, {0:1, 1:2.2}, {0:1, 1:2.5} for the class_weight. In other words, we are doing a total of five cross-validations. \n",
    "4. This means we will tune n_estimators, max_depth, max_features, and criterion for each cross-validation using Hyperopt. We are also using Hyperopt five times. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857f44f-ae69-4164-af5c-3bfea6c60f92",
   "metadata": {},
   "source": [
    "### class_weight = {0: 1, 1: 1.3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e49317-14bc-4eae-b355-cbd4c50cea63",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from hyperopt import tpe, hp, fmin, STATUS_OK,Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt import Trials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ede4c4b-15eb-4d2b-b515-d60cea11585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = pd.read_csv(\"./data/final_feature_matrix.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9455272c-ec22-4126-9f4a-10acbe2fd203",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text_features.drop(\"fraudulent\", axis = 1).values\n",
    "y = text_features.fraudulent.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "901f57e4-a40f-49eb-855d-48ccb9a5923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [100, 150, 200, 250, 300]),\n",
    "    \"max_depth\": hp.uniform(\"max_depth\", 30, 50),\n",
    "    \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "    \"max_features\": hp.choice(\"max_features\", [10, 12, 14, 16, 18, 20, 22])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81b3db81-28e6-4cd9-a670-d8962170021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning_first(params):\n",
    "    clf = RandomForestClassifier(**params, class_weight = {0:1, 1:1.3})\n",
    "    acc = cross_val_score(clf, X, y, scoring=\"accuracy\").mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a89386f-fe1d-49c4-9b8d-567303895668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 100/100 [2:19:23<00:00, 83.64s/trial, best loss: -0.9792366598797917]\n",
      "Best: {'criterion': 0, 'max_depth': 34.6262742855114, 'max_features': 4, 'n_estimators': 1}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    fn=hyperparameter_tuning_first,\n",
    "    space = space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=100, \n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "print(\"Best: {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "515383a2-5f46-4fa4-8593-0f219c28cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_two = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [200, 300, 400]),\n",
    "    \"max_depth\": hp.uniform(\"max_depth\", 30, 40),\n",
    "    \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "    \"max_features\": hp.choice(\"max_features\", [20, 22, 24, 26])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1fc35962-395b-4e27-abf2-d20bf220d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning_second(params):\n",
    "    clf = RandomForestClassifier(**params, class_weight = {0:1, 1:1.6})\n",
    "    acc = cross_val_score(clf, X, y, scoring=\"accuracy\").mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06519935-e30a-49e8-891b-20e08bd0dc14",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 50/50 [2:18:12<00:00, 165.84s/trial, best loss: -0.9794464012045279]\n",
      "Best: {'criterion': 0, 'max_depth': 35.18631376404232, 'max_features': 2, 'n_estimators': 1}\n"
     ]
    }
   ],
   "source": [
    "trials_two = Trials()\n",
    "\n",
    "best_two = fmin(\n",
    "    fn=hyperparameter_tuning_second,\n",
    "    space = space_two, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=50, \n",
    "    trials=trials_two\n",
    ")\n",
    "\n",
    "print(\"Best: {}\".format(best_two))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d90c997-b90b-46f3-a4ef-cc7b5ae486d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_three = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [200, 300, 400]),\n",
    "    \"max_depth\": hp.uniform(\"max_depth\", 30, 40),\n",
    "    \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "    \"max_features\": hp.choice(\"max_features\", [24, 26, 28, 30])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d658617-04bb-4536-9f72-3327e22beb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning_thrid(params):\n",
    "    clf = RandomForestClassifier(**params, class_weight = {0:1, 1:1.9})\n",
    "    acc = cross_val_score(clf, X, y, scoring=\"accuracy\").mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "74db6604-e12c-407e-84d6-0c82b29eae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 50/50 [1:09:40<00:00, 83.60s/trial, best loss: -0.9797260237141397]\n",
      "Best: {'criterion': 0, 'max_depth': 32.19118649485558, 'max_features': 2, 'n_estimators': 0}\n"
     ]
    }
   ],
   "source": [
    "trials_three = Trials()\n",
    "\n",
    "best_three = fmin(\n",
    "    fn=hyperparameter_tuning_thrid,\n",
    "    space = space_three, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=50, \n",
    "    trials=trials_three\n",
    ")\n",
    "\n",
    "print(\"Best: {}\".format(best_three))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "77c71914-8616-4ecd-a7d6-c6230c1c308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_four = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [200, 300, 400]),\n",
    "    \"max_depth\": hp.uniform(\"max_depth\", 30, 40),\n",
    "    \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "    \"max_features\": hp.choice(\"max_features\", [24, 26, 28, 30, 32])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a152e640-9a11-4700-a424-1a97328f4b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning_fourth(params):\n",
    "    clf = RandomForestClassifier(**params, class_weight = {0:1, 1:2.2})\n",
    "    acc = cross_val_score(clf, X, y, scoring=\"accuracy\").mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6593ba5-f136-4a16-819f-d9426f5e2ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 50/50 [2:40:56<00:00, 193.13s/trial, best loss: -0.9793764466920706]\n",
      "Best: {'criterion': 0, 'max_depth': 38.834973080192476, 'max_features': 3, 'n_estimators': 2}\n"
     ]
    }
   ],
   "source": [
    "trials_four = Trials()\n",
    "\n",
    "best_four = fmin(\n",
    "    fn=hyperparameter_tuning_fourth,\n",
    "    space = space_four, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=50, \n",
    "    trials=trials_four\n",
    ")\n",
    "\n",
    "print(\"Best: {}\".format(best_four))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7db6e6ae-34a8-405a-8eaa-02e473475b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_five = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [200, 300, 400]),\n",
    "    \"max_depth\": hp.uniform(\"max_depth\", 30, 40),\n",
    "    \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "    \"max_features\": hp.choice(\"max_features\", [18, 20, 22, 24, 26])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "82ac24d2-2ad3-44fe-836c-f95f5b58afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning_fifth(params):\n",
    "    clf = RandomForestClassifier(**params, class_weight = {0:1, 1:2.5})\n",
    "    acc = cross_val_score(clf, X, y, scoring=\"accuracy\").mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "816b31d5-6f00-4679-bb04-383bb8f0a69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 50/50 [1:28:47<00:00, 106.54s/trial, best loss: -0.9791667053673345]\n",
      "Best: {'criterion': 0, 'max_depth': 38.22266362146147, 'max_features': 3, 'n_estimators': 0}\n"
     ]
    }
   ],
   "source": [
    "trials_five = Trials()\n",
    "\n",
    "best_five = fmin(\n",
    "    fn=hyperparameter_tuning_fifth,\n",
    "    space = space_five, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=50, \n",
    "    trials=trials_five\n",
    ")\n",
    "\n",
    "print(\"Best: {}\".format(best_five))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
